{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306d5bd4",
   "metadata": {},
   "source": [
    "# Get Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2b3374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mapclassify\n",
    "from utils_spatial import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "edb1b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country and Amenity\n",
    "###########################\n",
    "amenity = 'hospital'\n",
    "\n",
    "# Transportation profile\n",
    "###########################\n",
    "profile='driving'\n",
    "\n",
    "# Population of interest\n",
    "###########################\n",
    "minute = '15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1ea7d4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_coverage_dataset(amenity, population_, profile, minute):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load Population\n",
    "    population = gpd.read_file(scldatalake + \n",
    "                               'Development Data Partnership/'+\n",
    "                               'Facebook - High resolution population density map/'+\n",
    "                               f'public-fb-data/geojson/LAC/{population_}_4'+\n",
    "                               '.geojson')\n",
    "    population = population[~(population.isoalpha3.isna()) & (population.isoalpha3.isin(countries))]\n",
    "    population.population.sum()\n",
    "\n",
    "    # Load isochrones\n",
    "    # ToDo(rsanchezavalos) read from preprocess s3\n",
    "    isochrones_data = pd.read_csv(f\"../data/LAC_{amenity}_{profile}.csv\")\n",
    "    isochrones_data = isochrones_data[['isoalpha3', 'amenity', 'profile', 'minutes', 'multipolygon']]\n",
    "    isochrones_data = isochrones_data[~(isochrones_data['multipolygon'].isna())]\n",
    "\n",
    "    for minute in ['15', '30', '45']:\n",
    "\n",
    "        # Keep isochrones from selected time profile\n",
    "        isochrone = isochrones_data[isochrones_data.minutes == int(minute)].reset_index()\n",
    "        isochrone = isochrone[~(isochrone.multipolygon.isna())].reset_index()\n",
    "        isochrone['geometry'] = gpd.GeoSeries.from_wkt(isochrone['multipolygon'])\n",
    "        geom = gpd.GeoDataFrame(isochrone, geometry='geometry')\n",
    "        geom = geom[['isoalpha3', 'amenity', 'profile', 'minutes', 'multipolygon', 'geometry']]\n",
    "\n",
    "        # Quick Fix - some isochrones cover more than one country\n",
    "        output = []\n",
    "        for isoalpha3 in countries:\n",
    "            gdf_match_iso = sjoin(population[population.isoalpha3==isoalpha3], geom[geom.isoalpha3==isoalpha3], how='left')\n",
    "            output.append(gdf_match_iso)\n",
    "\n",
    "        # ToDo(rsanchezavalos) Check population inconsistencies - gdf_match.population.sum()\n",
    "        gdf_match = pd.concat(output)\n",
    "        gdf_match.population.sum()\n",
    "        del gdf_match['index_right']\n",
    "        gdf_match.loc[(gdf_match.profile.isna()), 'profile'] = profile\n",
    "        gdf_match.loc[(gdf_match.amenity.isna()), f'coverage_{minute}'] = 'uncovered'\n",
    "        gdf_match.loc[~(gdf_match.amenity.isna()), f'coverage_{minute}'] = 'covered'\n",
    "        gdf_match.loc[(gdf_match.population.isna()), 'population'] = 0\n",
    "        gdf_match.loc[(gdf_match.minutes.isna()), 'minutes'] = minute\n",
    "        gdf_match.loc[(gdf_match.amenity.isna()), 'amenity'] = amenity\n",
    "        gdf_match['value'] = np.log(gdf_match.population)\n",
    "        gdf_match.loc[(gdf_match['value']<0),'value']=0\n",
    "\n",
    "        out = gdf_match.groupby(['amenity', f'coverage_{minute}'])['population'].sum().reset_index()\n",
    "        out['pct'] = out.population/out.population.sum()*100\n",
    "\n",
    "        # Spatial joinworld - state level\n",
    "        # ToDo(rsanchezavalos)> calculate the spatial intersection to drop duplicates\n",
    "        gdf_match['index'] = gdf_match.index\n",
    "        test = sjoin(gdf_match, world_, how='left')\n",
    "        test = test.drop_duplicates(['index'])\n",
    "\n",
    "        # add national population\n",
    "        level_1 = test.groupby(['isoalpha3','admin_name', f'coverage_{minute}'])['population'].sum().reset_index()\n",
    "        t = level_1.groupby(['isoalpha3','admin_name'])['population'].sum().reset_index().rename(columns={'population':'poptot'})\n",
    "        level_1 = level_1.merge(t, on=['isoalpha3','admin_name'], how='left')\n",
    "        level_1['pct'] = level_1.population/level_1.poptot*100\n",
    "\n",
    "        level_1 = level_1[level_1.isoalpha3.isin(geom.isoalpha3)]\n",
    "\n",
    "        # fillna population for 100% coverage\n",
    "        temp = (level_1.groupby(['isoalpha3', 'admin_name'])['poptot']\n",
    "                .count().reset_index()\n",
    "                .query('poptot == 1'))[['isoalpha3', 'admin_name']]\n",
    "        temp[f'coverage_{minute}'] = 'uncovered'\n",
    "        level_1 = level_1.merge(temp, on=['isoalpha3', 'admin_name', f'coverage_{minute}'], how='outer')\n",
    "        level_1['poptot'] = level_1['poptot'].fillna(level_1.groupby(['isoalpha3', 'admin_name'])['poptot'].transform('max'))\n",
    "        level_1['population'] = level_1['population'].fillna(0)\n",
    "        level_1['pct'] = level_1['pct'].fillna(0)\n",
    "\n",
    "        # filter only uncovered\n",
    "        level_1 = level_1[level_1[f'coverage_{minute}']=='uncovered'].sort_values('population', ascending=False)\n",
    "\n",
    "        country_result = world_.merge(level_1, on=['isoalpha3','admin_name'], how='left')\n",
    "\n",
    "        output_path = f\"Geospatial infrastructure/Healthcare Facilities/coverage/coverage_{population_}_{minute}.csv\"\n",
    "        files = [object_ for object_ in s3bucket.objects.filter(Prefix=output_path)]\n",
    "\n",
    "        if len(files) > 0:\n",
    "            country_result.to_csv(scldatalake + output_path,index=False)\n",
    "            print(\"File has been successfully uploaded to SCLData\")\n",
    "\n",
    "        else:\n",
    "            country_result.to_csv(f'../data/coverage_{population_}_{minute}.csv',index=False)\n",
    "            print('Please manually upload the file {0} in SCLData'.format(output_path))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# state level geoms\n",
    "level='2'\n",
    "world = (gpd.read_file(scldatalake +\n",
    "                      'Geospatial Basemaps/Cartographic Boundary Files/world/level-1/world-level-1.zip')\n",
    "         .rename(columns={\"GID_0\":\"isoalpha3\", 'NAME_1':'admin_name'}))\n",
    "world = world[(world.isoalpha3.isin(countries))]\n",
    "\n",
    "# Population of interest\n",
    "###########################\n",
    "for population_ in ['total_population', 'women_of_reproductive_age_15_49', \n",
    "                    'youth_15_24', 'elderly_60_plus']:\n",
    "    create_coverage_dataset(amenity, population_, profile, minute)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
